{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12875766,"sourceType":"datasetVersion","datasetId":8145193}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================================================\n# Step 0: Environment Setup\n# ================================================================\nimport os\n# Optional: Enable CUDA launch blocking for more precise error messages (slower training)\n# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\n# Install necessary libraries\n!pip install -q \"monai[tqdm, nibabel]\" itk simpleitk tqdm\n!pip install -q \"monai[tqdm, nibabel]\" itk simpleitk tqdm\n\nprint(\"Libraries installed/checked.\")\n\n# ================================================================\n# Step 1: Imports\n# ================================================================\nimport torch\nimport monai\nfrom monai.networks.nets import SwinUNETR\nfrom monai.data import (\n    DataLoader,\n    Dataset,\n    CacheDataset,\n    decollate_batch\n)\nfrom monai.transforms import (\n    AsDiscrete,\n    Compose,\n    LoadImaged,\n    MapTransform,\n    Orientationd,\n    RandFlipd,\n    RandCropByPosNegLabeld,\n    RandShiftIntensityd,\n    ScaleIntensityRanged,\n    Spacingd,\n    EnsureTyped,\n    EnsureChannelFirstd,\n    MapLabelValued # Import the label mapping transform\n)\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\nfrom monai.inferers import sliding_window_inference\nimport glob\nimport time\nfrom tqdm import tqdm\n\nprint(\"Imports successful.\")\n\n# ================================================================\n# Step 2: Define Data Paths\n# ================================================================\n# This is the correct main directory for your dataset\ndata_dir = \"/kaggle/input/panther-task1/\"\n\n# Use the correct subfolders and the .mha file extension\nimage_files_glob = os.path.join(data_dir, \"ImagesTr\", \"*.mha\")\nlabel_files_glob = os.path.join(data_dir, \"LabelsTr\", \"*.mha\")\n\nimage_files = sorted(glob.glob(image_files_glob))\nlabel_files = sorted(glob.glob(label_files_glob))\n\n# --- DEBUGGING: Check if files were found ---\nprint(f\"Searching for images at: {image_files_glob}\")\nprint(f\"Found {len(image_files)} image files.\")\nprint(f\"Searching for labels at: {label_files_glob}\")\nprint(f\"Found {len(label_files)} label files.\")\n\nif not image_files or not label_files:\n    raise FileNotFoundError(\"Could not find image or label files. Please double-check the paths and extensions.\")\nif len(image_files) != len(label_files):\n    print(f\"Warning: Mismatch in file counts. Found {len(image_files)} images and {len(label_files)} labels.\")\n# ---------------------------------------------\n\ndata_dicts = [\n    {\"image\": img_path, \"label\": lbl_path}\n    for img_path, lbl_path in zip(image_files, label_files)\n]\n\n# Split data (e.g., 80% train, 20% val)\nsplit_point = int(len(data_dicts) * 0.8)\nif split_point == 0 and len(data_dicts) > 0:\n    split_point = 1 # Ensure at least one file for training if dataset is very small\n\ntrain_files, val_files = data_dicts[:split_point], data_dicts[split_point:]\n\n# --- DEBUGGING: Check if lists are populated ---\nprint(f\"Total data dicts: {len(data_dicts)}\")\nprint(f\"Training files: {len(train_files)}\")\nprint(f\"Validation files: {len(val_files)}\")\n\nif not train_files and len(data_dicts) > 0:\n     raise ValueError(\"train_files list is empty, but data was found. Check your data split logic.\")\nif not train_files and not val_files:\n    raise ValueError(\"Both train_files and val_files are empty. No data was loaded.\")\n# ---------------------------------------------\nprint(\"Data paths defined and split.\")\n\n# ================================================================\n# Step 3: Define MONAI Transforms\n# ================================================================\npatch_size = (96, 96, 96)  # The size of patches cropped from volumes\nnum_samples = 4 # Number of patches to extract from each volume during training\n\n# === Define train_transforms ===\ntrain_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"], reader=\"ITKReader\"),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n        # Map label value 2 to 0 (background)\n        MapLabelValued(\n            keys=\"label\",\n            orig_labels=[0, 1, 2],\n            target_labels=[0, 1, 0]\n        ),\n        # --- Pre-processing ---\n        Spacingd(\n            keys=[\"image\", \"label\"],\n            pixdim=(1.5, 1.5, 1.5), # Resample to isotropic 1.5mm spacing\n            mode=(\"bilinear\", \"nearest\"), # Bilinear for image, nearest for label\n        ),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Reorient to RAS+\n        # Scale intensity (example range for CT/MRI, adjust if necessary)\n        ScaleIntensityRanged(\n            keys=[\"image\"],\n            a_min=-1000, a_max=1000,\n            b_min=0.0, b_max=1.0, clip=True,\n        ),\n        # --- Augmentation & Cropping ---\n        RandCropByPosNegLabeld(\n            keys=[\"image\", \"label\"],\n            label_key=\"label\",\n            spatial_size=patch_size,\n            pos=1, # Ratio of positive samples (with label > 0)\n            neg=1, # Ratio of negative samples (background)\n            num_samples=num_samples, # Number of patches per volume\n            image_key=\"image\",\n            image_threshold=0, # Threshold to consider foreground in image\n        ),\n        # --- More Augmentations ---\n        RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.10),\n        RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.10),\n        RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.10),\n        RandShiftIntensityd(keys=[\"image\"], offsets=0.10, prob=0.50),\n        EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32), # Ensure float type\n    ]\n)\n\n# === Define val_transforms SEPARATELY ===\nval_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"], reader=\"ITKReader\"),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n         # Map label value 2 to 0 (background)\n        MapLabelValued(\n            keys=\"label\",\n            orig_labels=[0, 1, 2],\n            target_labels=[0, 1, 0]\n        ),\n        # --- Pre-processing (same as train, without augmentation/cropping) ---\n        Spacingd(\n            keys=[\"image\", \"label\"],\n            pixdim=(1.5, 1.5, 1.5),\n            mode=(\"bilinear\", \"nearest\"),\n        ),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        ScaleIntensityRanged(\n            keys=[\"image\"],\n            a_min=-1000, a_max=1000,\n            b_min=0.0, b_max=1.0, clip=True,\n        ),\n        EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32), # Ensure float type\n    ]\n)\nprint(\"Transforms defined.\")\n\n# ================================================================\n# Step 4: Create Datasets and DataLoaders\n# ================================================================\n# Use CacheDataset for faster training iterations by caching transformed data\n# Adjust cache_num based on available RAM in your Kaggle session\ntrain_ds = CacheDataset(\n    data=train_files,\n    transform=train_transforms,\n    cache_num=24, # Number of items to cache, adjust based on RAM\n    cache_rate=1.0, # Cache all items specified by cache_num\n    num_workers=4, # Number of parallel workers for caching\n)\nval_ds = CacheDataset(\n    data=val_files,\n    transform=val_transforms,\n    cache_num=6, # Cache fewer validation items\n    cache_rate=1.0,\n    num_workers=4,\n)\n\n# DataLoader setup\n# Batch size 1 is common for 3D SwinUNETR on T4 due to memory limits.\n# Effective batch size becomes batch_size * num_samples from RandCropByPosNegLabeld\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=torch.cuda.is_available())\n\nprint(\"Datasets and DataLoaders created.\")\n\n# ================================================================\n# Step 5: Define Model, Loss, and Optimizer\n# ================================================================\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --- Add GPU Memory Check ---\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    # Clear cache before creating model\n    torch.cuda.empty_cache()\n    print(f\"Allocated Memory before model: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n    print(f\"Cached Memory before model: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n# -----------------------------\n\n# Define number of output classes (background + tumor)\nnum_out_channels = 2\n\n# Define the SwinUNETR model with reduced size for T4\nmodel = SwinUNETR(\n    in_channels=1,            # Single channel input (e.g., MRI/CT)\n    out_channels=num_out_channels, # Number of segmentation classes\n    patch_size=2,             # Initial patch embedding size (usually 2 or 4)\n    feature_size=12,          # Reduced feature size for T4 memory\n    use_checkpoint=True,      # Gradient checkpointing to save memory\n    spatial_dims=3            # Explicitly state 3D model\n).to(device)\n\nprint(\"Model successfully created and moved to device.\")\n\n# Loss function: Combination of Dice and Cross-Entropy\nloss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n\n# Optimizer: AdamW is often used with Transformers\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n\n# Automatic Mixed Precision (AMP) Scaler\nscaler = torch.amp.GradScaler('cuda')\n\nprint(\"Model, Loss, Optimizer defined.\")\n# ================================================================\n# Step 6: The Training and Validation Loop\n# ================================================================\n\n# --- INSERT START/RESUME CONFIGURATION HERE ---\n# 1. Define the checkpoint file path\ncheckpoint_file = \"swinunetr_checkpoint_latest.pth\" \n# This file will be saved in /kaggle/working/\n# Make sure to set your previous run's OUTPUT as an INPUT DATA source\n# if you want to load from a previous Kaggle session.\n\nstart_epoch = 0\nbest_val_loss = float('inf') \n\n# 2. Check for existing checkpoint and resume if found\ntry:\n    if os.path.exists(checkpoint_file):\n        # NOTE: If resuming from a previous Kaggle session, the file will be\n        # in the input directory, e.g., '/kaggle/input/your-prev-notebook-output/swinunetr_checkpoint_latest.pth'\n        # Adjust the path accordingly!\n        print(f\"Loading checkpoint from {checkpoint_file}...\")\n        \n        # Load the checkpoint dictionary\n        checkpoint = torch.load(checkpoint_file, map_location=device)\n        \n        # Load the states\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scaler.load_state_dict(checkpoint['scaler_state_dict']) # Also load AMP scaler!\n        start_epoch = checkpoint['epoch'] + 1\n        best_val_loss = checkpoint['best_val_loss']\n        \n        print(f\"Resumed training from Epoch {start_epoch}. Best Val Loss so far: {best_val_loss:.4f}\")\n        \n    # If the file exists but we can't load it, we'll proceed from start_epoch = 0.\nexcept Exception as e:\n    print(f\"Could not load checkpoint: {e}. Starting training from Epoch 0.\")\n    start_epoch = 0 # Reset to start from beginning if load fails\n# --- END INSERT ---\nmax_epochs = 100\nbest_val_loss = float('inf') # Initialize best validation loss tracking\n\n# Define post-processing transforms for calculating metrics\npost_pred = AsDiscrete(argmax=True, to_onehot=num_out_channels)\npost_label = AsDiscrete(to_onehot=num_out_channels)\n# Define Dice metric calculation\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n\nprint(\"Starting Training...\")\n\nfor epoch in range(start_epoch, max_epochs): # <--- MODIFIED RANGE!\n    start_time = time.time()\n    print(\"-\" * 10)\n    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n\n    # --- Training Phase ---\n    model.train()\n    epoch_loss = 0\n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n\n    for step, batch_data in progress_bar:\n        try:\n            inputs = batch_data[\"image\"].to(device)\n            labels = batch_data[\"label\"].to(device)\n\n            optimizer.zero_grad()\n\n            # Use Automatic Mixed Precision (AMP)\n            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = model(inputs)\n                loss = loss_function(outputs, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"train_loss\": f\"{epoch_loss / (step + 1):.4f}\"})\n\n        except Exception as e:\n            print(f\"\\nError during training step {step}: {e}\")\n            # Optionally: break or continue\n            break # Stop epoch on error\n\n    avg_epoch_loss = epoch_loss / len(train_loader) if len(train_loader) > 0 else 0\n    print(f\"Average Train Loss: {avg_epoch_loss:.4f}\")\n\n    # --- Validation Phase ---\n    model.eval()\n    val_loss = 0\n    dice_metric.reset() # Reset metric before validation\n\n    with torch.no_grad():\n        val_progress_bar = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n        for val_step, val_batch_data in val_progress_bar:\n            # === START OF CORRECTED BLOCK ===\n            try:\n                val_inputs = val_batch_data[\"image\"].to(device)\n                val_labels = val_batch_data[\"label\"].to(device)\n\n                # Use AMP for validation inference as well\n                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n                    # === FIX 1: USE SLIDING WINDOW INFERENCE ===\n                    roi_size = patch_size # (96, 96, 96) from Step 3\n                    sw_batch_size = 4 # Number of patches per inference window\n                    val_outputs = sliding_window_inference(\n                        val_inputs,\n                        roi_size,\n                        sw_batch_size,\n                        model,\n                        overlap=0.5\n                    )\n                    \n                    # Calculate loss (still inside the 'with' block)\n                    v_loss = loss_function(val_outputs, val_labels)\n\n                # === FIX 2: CORRECTED INDENTATION ===\n                # These lines are INSIDE the 'try' block\n                # but OUTSIDE the 'with torch.amp.autocast' block.\n\n                # Calculate Dice score - decollate first!\n                val_outputs_list = decollate_batch(val_outputs)\n                val_labels_list = decollate_batch(val_labels)\n\n                # Apply post-processing\n                val_outputs_processed = [post_pred(i) for i in val_outputs_list]\n                val_labels_processed = [post_label(i) for i in val_labels_list]\n\n                # Compute metric for current batch\n                dice_metric(y_pred=val_outputs_processed, y=val_labels_processed)\n\n                val_loss += v_loss.item()\n                val_progress_bar.set_postfix({\"val_loss\": f\"{val_loss / (val_step + 1):.4f}\"})\n\n            except Exception as e:\n                print(f\"\\nError during validation step {val_step}: {e}\")\n                # Optionally: break or continue\n                break # Stop validation on error\n            # === END OF CORRECTED BLOCK ===\n\n    avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n    # Aggregate the final mean dice result across all validation batches\n    try:\n        mean_dice = dice_metric.aggregate().item()\n    except Exception as e:\n        print(f\"Could not aggregate Dice metric: {e}\")\n        mean_dice = 0.0\n\n    end_time = time.time()\n    epoch_duration = end_time - start_time\n\n    print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n    print(f\"Mean Validation Dice (tumor class): {mean_dice:.4f}\")\n    print(f\"Epoch Duration: {epoch_duration:.2f} seconds\")\n\n   # --- Model Checkpointing and Saving Logic ---\n\n# 1. Create the full checkpoint dictionary\ncheckpoint = {\n    'epoch': epoch,\n    'best_val_loss': best_val_loss, # Save the current best loss\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scaler_state_dict': scaler.state_dict(), # Save the AMP scaler state\n    'val_dice': mean_dice\n}\n\n# 2. Always save the LATEST checkpoint (important for resuming)\nlatest_checkpoint_path = \"swinunetr_checkpoint_latest.pth\"\ntorch.save(checkpoint, latest_checkpoint_path)\nprint(f\"Saved LATEST Checkpoint to {latest_checkpoint_path}\")\n\n# 3. Save the BEST model based on validation loss\nif avg_val_loss < best_val_loss:\n    best_val_loss = avg_val_loss\n    # Save a separate file for the best model weights only (for final submission/inference)\n    best_model_path = \"best_model_swinunetr.pth\"\n    torch.save(model.state_dict(), best_model_path)\n    print(f\"Saved BEST Model (Val Loss: {best_val_loss:.4f}, Val Dice: {mean_dice:.4f})\")\n\n# ... (rest of the epoch end code)\n    # Optional: Clear CUDA cache after epoch if memory is tight\n    torch.cuda.empty_cache()\n\n# --- End of Training Loop ---\nprint(\"\\nTraining Finished!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T14:50:58.707951Z","iopub.execute_input":"2025-11-06T14:50:58.708460Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/28.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mLibraries installed/checked.\n","output_type":"stream"},{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-11-06 14:53:03.616429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762440783.823930      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762440783.885195      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nmonai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n","output_type":"stream"},{"name":"stdout","text":"Imports successful.\nSearching for images at: /kaggle/input/panther-task1/ImagesTr/*.mha\nFound 92 image files.\nSearching for labels at: /kaggle/input/panther-task1/LabelsTr/*.mha\nFound 92 label files.\nTotal data dicts: 92\nTraining files: 73\nValidation files: 19\nData paths defined and split.\nTransforms defined.\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\nLoading dataset: 100%|██████████| 6/6 [00:05<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Datasets and DataLoaders created.\nUsing device: cuda:0\nGPU: Tesla T4\nTotal Memory: 15.83 GB\nAllocated Memory before model: 0.00 GB\nCached Memory before model: 0.00 GB\nModel successfully created and moved to device.\nModel, Loss, Optimizer defined.\nStarting Training...\n----------\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 73/73 [01:28<00:00,  1.22s/it, train_loss=0.9483]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.9483\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:22<00:00,  4.36s/it, val_loss=0.8152]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.8152\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 172.34 seconds\n----------\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.30s/it, train_loss=0.7732]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.7732\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.7450]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.7450\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 180.39 seconds\n----------\nEpoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:35<00:00,  1.31s/it, train_loss=0.7264]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.7264\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.7092]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.7092\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 181.72 seconds\n----------\nEpoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:35<00:00,  1.31s/it, train_loss=0.6972]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6972\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.6847]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6847\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 181.52 seconds\n----------\nEpoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.29s/it, train_loss=0.6740]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6740\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.44s/it, val_loss=0.6652]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6652\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.85 seconds\n----------\nEpoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:31<00:00,  1.26s/it, train_loss=0.6562]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6562\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.43s/it, val_loss=0.6502]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6502\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 176.61 seconds\n----------\nEpoch 7/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.28s/it, train_loss=0.6424]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6424\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.42s/it, val_loss=0.6383]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6383\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.12 seconds\n----------\nEpoch 8/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.28s/it, train_loss=0.6319]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6319\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.41s/it, val_loss=0.6272]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6272\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.03 seconds\n----------\nEpoch 9/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.27s/it, train_loss=0.6218]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6218\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.42s/it, val_loss=0.6200]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6200\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 177.67 seconds\n----------\nEpoch 10/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:31<00:00,  1.25s/it, train_loss=0.6140]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6140\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.43s/it, val_loss=0.6093]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6093\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 176.32 seconds\n----------\nEpoch 11/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.29s/it, train_loss=0.6042]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.6042\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.41s/it, val_loss=0.6023]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.6023\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.48 seconds\n----------\nEpoch 12/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.28s/it, train_loss=0.5983]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5983\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.43s/it, val_loss=0.5974]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5974\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 177.96 seconds\n----------\nEpoch 13/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.28s/it, train_loss=0.5914]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5914\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.43s/it, val_loss=0.5910]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5910\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.41 seconds\n----------\nEpoch 14/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.29s/it, train_loss=0.5840]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5840\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.42s/it, val_loss=0.5871]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5871\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.49 seconds\n----------\nEpoch 15/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:32<00:00,  1.27s/it, train_loss=0.5764]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5764\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.42s/it, val_loss=0.5806]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5806\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 177.44 seconds\n----------\nEpoch 16/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:32<00:00,  1.27s/it, train_loss=0.5711]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5711\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.42s/it, val_loss=0.5755]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5755\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 177.12 seconds\n----------\nEpoch 17/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.29s/it, train_loss=0.5666]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5666\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.43s/it, val_loss=0.5714]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5714\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.72 seconds\n----------\nEpoch 18/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.29s/it, train_loss=0.5596]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5596\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:23<00:00,  4.42s/it, val_loss=0.5672]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5672\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.56 seconds\n----------\nEpoch 19/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.30s/it, train_loss=0.5534]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5534\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.5640]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5640\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 180.27 seconds\n----------\nEpoch 20/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:33<00:00,  1.28s/it, train_loss=0.5488]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5488\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.5596]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5596\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 179.56 seconds\n----------\nEpoch 21/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:32<00:00,  1.27s/it, train_loss=0.5470]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5470\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.49s/it, val_loss=0.5595]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5595\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 178.31 seconds\n----------\nEpoch 22/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.30s/it, train_loss=0.5406]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5406\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.5533]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5533\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 180.81 seconds\n----------\nEpoch 23/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.29s/it, train_loss=0.5373]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5373\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.47s/it, val_loss=0.5500]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5500\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 179.85 seconds\n----------\nEpoch 24/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.29s/it, train_loss=0.5328]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5328\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:25<00:00,  4.48s/it, val_loss=0.5483]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5483\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 179.83 seconds\n----------\nEpoch 25/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining: 100%|██████████| 73/73 [01:34<00:00,  1.30s/it, train_loss=0.5292]","output_type":"stream"},{"name":"stdout","text":"Average Train Loss: 0.5292\n","output_type":"stream"},{"name":"stderr","text":"\nValidation: 100%|██████████| 19/19 [01:24<00:00,  4.45s/it, val_loss=0.5447]","output_type":"stream"},{"name":"stdout","text":"Average Validation Loss: 0.5447\nMean Validation Dice (tumor class): 0.0000\nEpoch Duration: 179.80 seconds\n----------\nEpoch 26/100\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  38%|███▊      | 28/73 [00:38<00:55,  1.24s/it, train_loss=0.5292]","output_type":"stream"}],"execution_count":null}]}